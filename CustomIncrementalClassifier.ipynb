{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:57:34.802059800Z",
     "start_time": "2023-08-15T16:57:34.661467600Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '_utils_internal'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mavalanche\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbenchmarks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m benchmark_with_validation_stream, nc_benchmark\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\avalanche\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mavalanche\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m benchmarks\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mavalanche\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m evaluation\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mavalanche\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logging\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\avalanche\\benchmarks\\__init__.py:11\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03mThe :py:mod:`benchmarks` module provides a set of utilities that can be used for\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mhandling and generating your continual learning data stream. In the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;124;03mare made available.\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscenarios\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclassic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\avalanche\\benchmarks\\scenarios\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeneric_definitions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclassification_scenario\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeneric_scenario_creation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\avalanche\\benchmarks\\scenarios\\generic_definitions.py:48\u001B[0m\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     37\u001B[0m         TypeVar,\n\u001B[0;32m     38\u001B[0m         Tuple,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     44\u001B[0m         Generic,\n\u001B[0;32m     45\u001B[0m     )\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping_extensions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Protocol, runtime_checkable\n\u001B[1;32m---> 48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mavalanche\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbenchmarks\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m make_classification_dataset\n\u001B[0;32m     51\u001B[0m TCLScenario \u001B[38;5;241m=\u001B[39m TypeVar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTCLScenario\u001B[39m\u001B[38;5;124m\"\u001B[39m, bound\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCLScenario\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     52\u001B[0m TCLExperience \u001B[38;5;241m=\u001B[39m TypeVar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTCLExperience\u001B[39m\u001B[38;5;124m\"\u001B[39m, bound\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCLExperience\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\avalanche\\benchmarks\\utils\\__init__.py:3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclassification_dataset\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets_from_filelists\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtorchvision_wrapper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\avalanche\\benchmarks\\utils\\datasets_from_filelists.py:25\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpath\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tensor\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m crop\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mavalanche\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbenchmarks\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m make_classification_dataset\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_image_loader\u001B[39m(path):\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\__init__.py:5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datasets\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m io\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m models\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\datasets\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_optical_flow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KittiFlow, Sintel, FlyingChairs, FlyingThings3D, HD1K\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcaltech\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Caltech101, Caltech256\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mceleba\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CelebA\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\datasets\\_optical_flow.py:12\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _read_png_16\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m verify_str_arg\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VisionDataset\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\io\\__init__.py:8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _log_api_usage_once\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_load_gpu_decoder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _HAS_GPU_VIDEO_DECODER\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n\u001B[0;32m     10\u001B[0m     _HAS_GPU_VIDEO_DECODER \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\io\\_load_gpu_decoder.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mextension\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _load_library\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      5\u001B[0m     _load_library(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDecoder\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torchvision\\extension.py:20\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     19\u001B[0m     lib_path \u001B[38;5;241m=\u001B[39m _get_extension_path(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_C\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 20\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlib_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m     _HAS_OPS \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_has_ops\u001B[39m():  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torch\\_ops.py:250\u001B[0m, in \u001B[0;36m_Ops.load_library\u001B[1;34m(self, path)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mexecutable \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch_deploy\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 250\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_utils_internal\u001B[49m\u001B[38;5;241m.\u001B[39mresolve_library_path(path)\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dl_open_guard():\n\u001B[0;32m    252\u001B[0m     \u001B[38;5;66;03m# Import the shared library into the process, thus running its\u001B[39;00m\n\u001B[0;32m    253\u001B[0m     \u001B[38;5;66;03m# static (global) initialization code in order to register custom\u001B[39;00m\n\u001B[0;32m    254\u001B[0m     \u001B[38;5;66;03m# operators with the JIT.\u001B[39;00m\n\u001B[0;32m    255\u001B[0m     ctypes\u001B[38;5;241m.\u001B[39mCDLL(path)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch' has no attribute '_utils_internal'"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "from avalanche.benchmarks import benchmark_with_validation_stream, nc_benchmark\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from avalanche.training.supervised import EWC, icarl, Naive, CWRStar, Replay, GDumb, LwF, GEM, AGEM, EWC\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, loss_metrics, timing_metrics, \\\n",
    "    cpu_usage_metrics, disk_usage_metrics\n",
    "from avalanche.training.plugins import EWCPlugin, AGEMPlugin, GEMPlugin, ReplayPlugin, CWRStarPlugin, RWalkPlugin\n",
    "from avalanche.logging import InteractiveLogger, TensorboardLogger, TextLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training import ExemplarsBuffer, ReservoirSamplingBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class TorchDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filePath):\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        # Read CSV\n",
    "        data = pd.read_csv(filePath)\n",
    "        # drop one class from dataset to make it 30 classes\n",
    "        data = data[data['label'] != 30]\n",
    "\n",
    "        self.X = data.iloc[:, :-1].values\n",
    "        self.targets = data.iloc[:, -1].values\n",
    "\n",
    "        # Feature Scale if you want\n",
    "\n",
    "        # Convert to Torch Tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(self.targets, dtype=torch.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.X[item], self.targets[item]\n",
    "\n",
    "\n",
    "def prep_benchmark(train_loc, test_loc):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(device)\n",
    "\n",
    "    hdata_train = TorchDataset(train_loc)\n",
    "    hdata_test = TorchDataset(test_loc)\n",
    "\n",
    "    return benchmark_with_validation_stream(nc_benchmark(train_dataset=hdata_train, test_dataset=hdata_test\n",
    "                                                         , shuffle=True, seed=1234, task_labels=True, n_experiences=5,\n",
    "                                                         one_dataset_per_exp=True,\n",
    "\n",
    "                                                         ))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T16:53:34.191549Z"
    }
   },
   "id": "6b61e45f9d765b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from avalanche.benchmarks import CLExperience\n",
    "from avalanche.models import DynamicModule\n",
    "\n",
    "\n",
    "# implement a Incremental classifier with a custom classifier\n",
    "class IncrementalClassifierD1(DynamicModule):\n",
    "    \"\"\"\n",
    "    Output layer that incrementally adds units whenever new classes are\n",
    "    encountered.\n",
    "\n",
    "    Typically used in class-incremental benchmarks where the number of\n",
    "    classes grows over time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        initial_out_features=2,\n",
    "        masking=True,\n",
    "        mask_value=-1000,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param in_features: number of input features.\n",
    "        :param initial_out_features: initial number of classes (can be\n",
    "            dynamically expanded).\n",
    "        :param masking: whether unused units should be masked (default=True).\n",
    "        :param mask_value: the value used for masked units (default=-1000).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.masking = masking\n",
    "        self.mask_value = mask_value\n",
    "        self.features = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=1, out_channels=32, padding='same',  kernel_size=3,),\n",
    "        nn.MaxPool1d(4),\n",
    "        nn.Conv1d(in_channels=32, out_channels=32, padding='same',  kernel_size=3),\n",
    "        nn.MaxPool1d(4),\n",
    "        nn.Conv1d(in_channels=32, out_channels=16, padding='same',  kernel_size=3),\n",
    "        nn.MaxPool1d(4),\n",
    "        nn.Conv1d(in_channels=16, out_channels=16, padding='same',  kernel_size=3),\n",
    "        nn.MaxPool1d(4),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(nn.Linear(256, initial_out_features))\n",
    "\n",
    "        # self.classifier = torch.nn.Linear(in_features, initial_out_features)\n",
    "        au_init = torch.zeros(initial_out_features, dtype=torch.bool)\n",
    "        self.register_buffer(\"active_units\", au_init)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def adaptation(self, experience: CLExperience):\n",
    "        \"\"\"If `dataset` contains unseen classes the classifier is expanded.\n",
    "\n",
    "        :param experience: data from the current experience.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        in_features = self.classifier.in_features\n",
    "        old_nclasses = self.classifier.out_features\n",
    "        curr_classes = experience.classes_in_this_experience\n",
    "        new_nclasses = max(self.classifier.out_features, max(curr_classes) + 1)\n",
    "\n",
    "        # update active_units mask\n",
    "        if self.masking:\n",
    "            if old_nclasses != new_nclasses:  # expand active_units mask\n",
    "                old_act_units = self.active_units\n",
    "                self.active_units = torch.zeros(new_nclasses, dtype=torch.bool)\n",
    "                self.active_units[: old_act_units.shape[0]] = old_act_units\n",
    "            # update with new active classes\n",
    "            if self.training:\n",
    "                self.active_units[curr_classes] = 1\n",
    "\n",
    "        # update classifier weights\n",
    "        if old_nclasses == new_nclasses:\n",
    "            return\n",
    "        old_w, old_b = self.classifier.weight, self.classifier.bias\n",
    "        self.classifier = torch.nn.Linear(in_features, new_nclasses)\n",
    "        self.classifier.weight[:old_nclasses] = old_w\n",
    "        self.classifier.bias[:old_nclasses] = old_b\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        \"\"\"compute the output given the input `x`. This module does not use\n",
    "        the task label.\n",
    "\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = self.classifier(x, task_labels)#TODO: previously\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        out = torch.log_softmax(x, dim=1)\n",
    "        \n",
    "        # out = self.classifier(x)\n",
    "        if self.masking:\n",
    "            out[..., torch.logical_not(self.active_units)] = self.mask_value\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T16:53:34.193549200Z"
    }
   },
   "id": "b59ca7a8c756557a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model4 = IncrementalClassifierD1(in_features=4096, masking=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:53:34.195550400Z",
     "start_time": "2023-08-15T16:53:34.194550600Z"
    }
   },
   "id": "bf7b91c2f6281acd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "benchmark = prep_benchmark(train_loc='./DATA/TRAIN_DATA.csv', test_loc='./DATA/TEST_DATA.csv')\n",
    "\n",
    "# log to Tensorboard\n",
    "tb_logger = TensorboardLogger()\n",
    "\n",
    "# log to text file\n",
    "text_logger = TextLogger(open('log.txt', 'a'))\n",
    "\n",
    "# print to stdout\n",
    "interactive_logger = InteractiveLogger()\n",
    "\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    timing_metrics(epoch=True, epoch_running=True),\n",
    "    forgetting_metrics(experience=True, stream=True),\n",
    "    cpu_usage_metrics(experience=True),\n",
    "    # confusion_matrix_metrics(num_classes=benchmark['inc_bench'].n_classes, save_image=False,\n",
    "    #                          stream=True),\n",
    "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loggers=[interactive_logger, text_logger, tb_logger]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-15T16:53:34.195550400Z"
    }
   },
   "id": "9ff077cc9b04cf06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cl_strategy = Naive(\n",
    "    model=model4,\n",
    "    optimizer=torch.optim.Adam(model4.parameters(), lr=0.001, ),\n",
    "    criterion=CrossEntropyLoss(),\n",
    "    train_mb_size=500, train_epochs=200, eval_mb_size=100,\n",
    "    # ewc_lambda=0.04,\n",
    "    evaluator=eval_plugin,\n",
    "    plugins=[ReplayPlugin(mem_size=10000, storage_policy=ReservoirSamplingBuffer(max_size=10000)),\n",
    "             RWalkPlugin()]\n",
    ")\n",
    "\n",
    "# TRAINING LOOP\n",
    "print('Starting experiment...')\n",
    "results = []\n",
    "model_incs = []\n",
    "classes_exp = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Start of experience: \", experience.current_experience)\n",
    "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
    "    # model_incs.append(model4.classifier.out_features)\n",
    "    classes_exp.append(experience.classes_in_this_experience)\n",
    "    # train returns a dictionary which contains all the metric values\n",
    "    res = cl_strategy.train(experience)\n",
    "    print('Training completed')\n",
    "\n",
    "    print('Computing accuracy on the whole test set')\n",
    "    # test also returns a dictionary which contains all the metric values\n",
    "    results.append(cl_strategy.eval(benchmark.test_stream))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:53:34.210548400Z",
     "start_time": "2023-08-15T16:53:34.195550400Z"
    }
   },
   "id": "69ad8d0996a04f2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
